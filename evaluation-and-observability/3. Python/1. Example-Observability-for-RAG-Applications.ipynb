{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observability and human feedback collection for a RAG application using knowledge bases for Amazon bedrock.\n",
    "\n",
    "### Context:\n",
    "In the following example, we will use a `Knowledge Base for Amazon Bedrock` that you have already created and add the request and response to an `Amazon Kinesis Data Firehose`. The Amazon Firehose will then apply a transformation on the data to flatten the nested JSON and created logical partitions in the data using `call_type` variable, which will ease data usage later when you query it in a database. \n",
    "\n",
    "The data transformation takes place using a `Transformation Lambda function` associated with the Amazon Kinesis Data Firehose. This configuration allows for data transformation without adding any latency to your application due to the transformation step. You can optionally disable the data flattening in the Amazon lambda function.\n",
    "\n",
    "### Prerequisite\n",
    "After successfully setting up the backend resources required using the provided `CloudFormation template` to gather necessary data on user requests, your custom metadata like latency, time to first token, tags, model responses, citations, and any other custom identifiers you would like to add (e.g., user_id/customer_id), you can now test if your observability architecture is working as expected and determine the latency introduced by adding this additional component to your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Important Note`: \n",
    "\n",
    "##### 1. Please use your AWS configuration to fill in the `config.py` file before running the code \n",
    "\n",
    "##### 2: Make sure you have upgraded your boto3 version to have at least `1.34.126` version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1:\n",
    "\n",
    "In the below section, we will go through the code that interacts with the Knowledge Base for Amazon Bedrock to retrieve and generate responses based on user questions. The code imports necessary libraries and modules, including the AWS SDK (boto3) and the observability custom module called `observability` that contains the `BedrockLogs` class for logging, evaluation, and observability purposes.\n",
    "\n",
    "It sets up AWS clients for Firehose, Bedrock Agent Runtime, and a boto3 session, and imports configuration values from a separate `config` module. The `retrieve_and_generate` function is defined, which takes a question and parameters as input, and calls the `bedrock_agent_runtime_client.retrieve_and_generate` method to retrieve and generate a response from the Amazon Bedrock Knowledge Base based on the provided question and configuration parameters.\n",
    "\n",
    "The `main` function is decorated with `@bedrock_logs.watch`, which logs and tracks the function call for observability purposes. `@bedrock_logs.watch` tracks first input argument, so, you can choose to pass a JSON and add any metadata according to your use case and the observability solution will track it. Similarly, the observability solution will also track all the return varaiable values. You can also log any custom metric like time to first token, time to last token, or any other custom metric of your choosing inside the decorated function and add it to the return statement so that it gets logged.\n",
    "\n",
    "Inside the `main` function, the `retrieve_and_generate` function is called with the user's question and generation configuration parameters. The response from the Knowledge Base is stored in the `application_metadata` dictionary, along with the generation parameters, and the generated response text is returned.\n",
    "\n",
    "The code also includes a helper function `generate_web_session_id` to generate a random session ID, which can be used as a custom identifier for tracking purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upgrading boto3 to the minimum required version and above.\n",
    "# ! pip install 'boto3>=1.34.126' -- upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import string\n",
    "import random\n",
    "\n",
    "# Custom Module:\n",
    "from observability import BedrockLogs\n",
    "\n",
    "# Import your configuration values\n",
    "from config import (\n",
    "    REGION, FIREHOSE_NAME, CRAWLER_NAME, MODEL_ARN, KB_ID, \n",
    "    APPLICATION_NAME, CUSTOM_TAG, GUARDRAIL_ID, GUARDRAIL_VERSION,\n",
    "    MAX_TOKENS, TEMPERATURE, TOP_P\n",
    ")\n",
    "\n",
    "# Initialize BedrockLogs in Local mode with feedback variables:\n",
    "# bedrock_logs = BedrockLogs(delivery_stream_name=FIREHOSE_NAME, \n",
    "#                            feedback_variables=True)\n",
    "\n",
    "# Initialize BedrockLogs in Local mode with feedback variables:\n",
    "bedrock_logs = BedrockLogs(delivery_stream_name='local', \n",
    "                           feedback_variables=True)\n",
    "\n",
    "# Create AWS clients\n",
    "boto3_session = boto3.session.Session()\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "# Function to generate a response from the Amazon Bedrock Knowledge Base\n",
    "def retrieve_and_generate(question, params):\n",
    "    if 'sessionId' in params.keys():   \n",
    "        return bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': question\n",
    "            },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': KB_ID,\n",
    "                    'modelArn': MODEL_ARN,\n",
    "                    'generationConfiguration': {\n",
    "                        'guardrailConfiguration': {\n",
    "                            'guardrailId': GUARDRAIL_ID,\n",
    "                            'guardrailVersion': GUARDRAIL_VERSION\n",
    "                        },\n",
    "                        'inferenceConfig': {\n",
    "                            'textInferenceConfig': {\n",
    "                                'maxTokens': MAX_TOKENS,\n",
    "                                'temperature': TEMPERATURE,\n",
    "                                'topP': TOP_P\n",
    "                            }\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            sessionId=params['sessionId']\n",
    "        )\n",
    "    else:\n",
    "        return bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': question\n",
    "            },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': KB_ID,\n",
    "                    'modelArn': MODEL_ARN,\n",
    "                    'generationConfiguration': {\n",
    "                        'guardrailConfiguration': {\n",
    "                            'guardrailId': GUARDRAIL_ID,\n",
    "                            'guardrailVersion': GUARDRAIL_VERSION\n",
    "                        },\n",
    "                        'inferenceConfig': {\n",
    "                            'textInferenceConfig': {\n",
    "                                'maxTokens': MAX_TOKENS,\n",
    "                                'temperature': TEMPERATURE,\n",
    "                                'topP': TOP_P\n",
    "                            }\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "# dummy value to demonstrate custom metadata:\n",
    "def generate_web_session_id(length=16):\n",
    "    # Define the characters to be used in the session ID\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    \n",
    "    # Generate a random string of the specified length\n",
    "    session_id = ''.join(random.choices(characters, k=length))\n",
    "    \n",
    "    return session_id\n",
    "\n",
    "# Example on how to deploy and track observability or evaluataion:\n",
    "@bedrock_logs.watch(call_type='Retrieve-and-Generate-with-KB')\n",
    "def main(application_metadata):\n",
    "    params = {\n",
    "        'guardrailId': GUARDRAIL_ID,\n",
    "        'guardrailVersion': GUARDRAIL_VERSION,\n",
    "        'maxTokens': MAX_TOKENS,\n",
    "        'temperature': TEMPERATURE,\n",
    "        'topP': TOP_P\n",
    "    }\n",
    "\n",
    "    response = retrieve_and_generate(application_metadata['question'], params)\n",
    "    application_metadata['model_response'] = response\n",
    "    return response['output']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important note on sensitive data:\n",
    "If you do not want the observability module to log a sensitive information, you can simply move that information into a second, third,... variable based on your design. Here are two example use cases:\n",
    "\n",
    "1. Where you want all input arguments to be a part of your logs:\n",
    "```python\n",
    "@bedrock_logs.watch(call_type='Retrieve-and-Generate-with-KB')\n",
    "def main(json_of_data_to_be_track):\n",
    "    # implement your metrics and functions\n",
    "    return None\n",
    "```\n",
    "    \n",
    "2. You do not want sensitive data or other custom data to become part of ythe logs:\n",
    "```python\n",
    "@bedrock_logs.watch(call_type='Retrieve-and-Generate-with-KB')\n",
    "def main(json_of_data_to_be_track, untracked_data< untracked_data2, untracked_json, etc...):\n",
    "    # implement your metrics and functions\n",
    "    return None\n",
    "```\n",
    "\n",
    "##### Track application logs or evaluation based on your use case:\n",
    "In the below cell, we will use the decorated function `main()` and pass a custom metadata json `application_metadata` to it. You can configure any custom value, tags, or any metric or an identifier that you want to be tracked here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = 'What is Amazon doing in the field of generative AI?'\n",
    "# your custom metrics or identifiers, for example:\n",
    "application_metadata = {\n",
    "    'webSessionId': generate_web_session_id(),\n",
    "    'userID': 'User-1',\n",
    "    'applicationName': APPLICATION_NAME,\n",
    "    'customTags': CUSTOM_TAG\n",
    "}\n",
    "\n",
    "# other custom metrics or identifiers\n",
    "dt = datetime.fromtimestamp(time.time(), tz=pytz.utc)\n",
    "application_metadata['request_time'] = dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "application_metadata['model_arn'] = MODEL_ARN\n",
    "application_metadata['question'] = question\n",
    "\n",
    "# Make the API call. There are three ways:\n",
    "# 1: if you have enabled local mode and with feedback mode:\n",
    "response, log, run_id, observation_id  = main(application_metadata)\n",
    "\n",
    "# 2: if you have enabled firehose mode and with feedback mode:\n",
    "# response, run_id, observation_id  = main(application_metadata)\n",
    "\n",
    "# 3: if you have disabled feedback mode:\n",
    "# response = main(application_metadata)\n",
    "\n",
    "# printing the run_id and observation_id for reference:\n",
    "print(f\"run_id: {run_id},\\nobservation_id: {observation_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2: Collecting feedback for your GenAI application responses.\n",
    "\n",
    "In this section, you are using the `run_id` and `observation_id` generated from the `main function` to collect feedback on the responses from your end-users or QA team. The code defines two functions, `observation_level_feedback` and `session_level_feedback`, both decorated with `@bedrock_logs.watch` to track the feedback collection process.\n",
    "\n",
    "The `call_type` variable in the decorator is used to create logical partitions in the collected data. This allows you to separate the feedback data based on whether it is collected at the observation level or the session level, making it easier to analyze and process the feedback data later.\n",
    "\n",
    "The `observation_level_feedback` function is designed to collect feedback at the observation level, which means feedback is associated with a specific `observation_id`. This function takes a dictionary as input, containing the `user_id`, `f_run_id` (the run_id associated with the feedback), `f_observation_id` (the observation_id associated with the feedback), and `actual_feedback` (the feedback itself, which can be a simple \"Thumbs-up\" or more detailed text).\n",
    "\n",
    "The `session_level_feedback` function is designed to collect feedback at the session level, which means feedback is associated with a specific `run_id`. The input parameters for this function are not provided in the code snippet.\n",
    "\n",
    "When using the feedback mechanism, it is crucial to always pass the `run_id` and `observation_id` for which the feedback is being collected like we did with `f_run_id` and `observation_id`. These identifiers act as keys for joining various logically partitioned datasets, allowing you to associate the feedback with the specific response generated by your GenAI application.\n",
    "\n",
    "The code demonstrates how the `observation_level_feedback` function can be called with a dictionary containing the necessary information, including a dummy `user_feedback` value of \"Thumbs-up\".\n",
    "\n",
    "By collecting feedback at the observation or session level and using the `call_type` variable to create logical partitions, you can effectively organize and analyze the feedback data, enabling you to evaluate the performance and quality of the responses, identify areas for improvement, and refine the knowledge base or model accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@bedrock_logs.watch(call_type='observation-feedback')\n",
    "def observation_level_feedback(feedback):\n",
    "    pass\n",
    "\n",
    "@bedrock_logs.watch(call_type='session-feedback')\n",
    "def session_level_feedback(feedback):\n",
    "    pass\n",
    "\n",
    "\n",
    "# defining a dummy user_feedback:\n",
    "user_feedback = 'Thumbs-up'\n",
    "\n",
    "observation_feedback_from_front_end = {\n",
    "    'user_id': 'User-1',\n",
    "    'f_run_id': run_id,\n",
    "    'f_observation_id': observation_id,\n",
    "    'actual_feedback': user_feedback\n",
    "}\n",
    "\n",
    "# log observation-feedback as a separate dataset based on call_type\n",
    "observation_level_feedback(observation_feedback_from_front_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_feedback = 'Amazing - this is fast and an awesome way to help the customers!'\n",
    "session_feedback_from_front_end = {\n",
    "    'user_id': 'User-1',\n",
    "    'f_run_id': run_id,\n",
    "    'actual_feedback': user_feedback\n",
    "}\n",
    "\n",
    "# session-feedback\n",
    "session_level_feedback(session_feedback_from_front_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "\n",
    "1. Now that your data is available in Amazon S3, you can `optionally` trigger the `Glue Crawler` to help you with the creation of Amazon `Athena tables`. These Athena tables can be used to create amazing dashboards for analyzing and visualizing the collected data.\n",
    "\n",
    "2. Using Athena and Amazon S3, you can perform detailed analysis for troubleshooting your application, response evaluation, or build analytical dashboards. The provided screenshots demonstrate how you can not only track metrics for your application but also incorporate any information logged via `@bedrock_logs.watch`, including custom data or metrics like latency, token metrics, cost-related metrics, and more.\n",
    "\n",
    "3. Below is an example dahsboard **(not a part of this solution)**. These dashboards serve as basic examples, showcasing the potential for visualizing and analyzing the collected data. By leveraging the power of Amazon Athena and S3, you can gain valuable insights into your GenAI application's performance, identify areas for improvement, and make data-driven decisions to enhance the overall user experience.\n",
    "\n",
    "**Executive Summary**\n",
    "![kb-observability-dashboard-example1.png](./images/kb-observability-dashboard-example1.png)\n",
    "![kb-observability-dashboard-example2.png](./images/kb-observability-dashboard-example2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
