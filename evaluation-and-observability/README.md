# Project Name: Bedrock-ICYM (I See You Monitoring)

## Observability Made Easy: Logging and Tracking for GenAI
Unleash the power of comprehensive logging! Integrate any metric into your functions, and our observability package will diligently track and record it.

## Observability and Evaluation Custom Solution for Amazon Bedrock Applications
This Python package provides a solution for observability, response evaluation, RAG evaluation, and tracking metadata for Amazon Bedrock applications, including Knowledge Bases, Agents, Invoke Model, Function Calling, and Guardrails. It leverages Amazon Kinesis Firehose to ingest data into an S3 bucket, enabling data analysis and visualization using services like Amazon Athena and Amazon QuickSight.

## Features
- **Security**: Your data never leaves your AWS and you control the information that gets logged.
- **Data Encryption in Transit**: Data is encrypted in transit via Amazon Kinesis Firehose.
- **Decorator Implementation**: The package uses a decorator-based approach to simplify the integration of observability logging and evaluation into your application functions.
- **Data Storage in Amazon S3**: Observability and evaluation data is stored in an Amazon S3 bucket for analysis and data visualization.
- **Amazon QuickSight Integration (Optional)**: You can optionally set up an Amazon QuickSight dashboard for visualizing the observability and evaluation data.
- **CloudFormation Support**: The package includes a CloudFormation template for easy deployment of the required AWS resources.
- **Boto3 and Python Version Support**: Supports Boto3 1.34.115 and above, and Python 3.10 and above.
- **Observability and Evaluation for Various Components**: Supports observability and evaluation for InvokeModel, Knowledge Bases for Amazon Bedrock, Agents for Amazon Bedrock, and Guardrails for Amazon Bedrock.
- **Custom Metadata and Tags**: Allows you to include custom metadata, tags, and session information in the observability and evaluation data.
- **Trace and Hierarchy Management**: Supports traces and hierarchy management when needed.
- **Citation Support for Knowledge Bases**: Supports citation tracking for Knowledge Bases.
- **Latency and Duration Tracking**: Tracks trace latency, logging latency, and total time to complete requests.
- **Local Logging Option**: Provides the option to use Amazon Kinesis Firehose or in-memory local logging for testing and development purposes.
- **Call Type Variable**: Allows you to create logical partitions in the data, enabling the creation of multiple datasets and linking them by `run_id` and `observation_id`. This feature can also be used to collect feedback from end-users or QA testers on model responses.
- **Response and Human-in-the-Loop Evaluation**: Supports evaluating the responses generated by the application to track quality and relevance, as well as enabling human-in-the-loop evaluation of performance and behavior using Knowledge Bases and Agents for Amazon Bedrock. This comprehensive approach provides insights to improve your generative AI application.
- **Knowledge Base Evaluation**: Supports evaluation of the performance and effectiveness of the Knowledge Bases used in the application.
- **Agent Evaluation**: Supports evaluation of the performance and behavior of the Agents used in the application.

## Usage
1. Complete the pre-requisites to use the custom solution.
2. Clone the observability.py file to your application environment.
3. Import the `BedrockLogs` class from the package:

```python
from observability import BedrockLogs
```

4. Initialize the `BedrockLogs` instance with the required parameters:

```python
bedrock_logs = BedrockLogs(
    delivery_stream_name='your-firehose-delivery-stream',
    experiment_id='your-experiment-id', # or use 'local' for testing
    feature_name='Agent',  # or 'KB', 'InvokeModel', etc.
    feedback_variables=True # to get run_id and observation id that can be used to collect user/QA feedback on model response.
)
```

5. Decorate the functions or methods you want to log and evaluate with the `@bedrock_logs.watch` decorator:

```python
@bedrock_logs.watch(capture_input=True, capture_output=True, call_type='<your-custom-dataset-name>')
def your_function(arg1, arg2): # only arg1 will be tracked to give you an option to not log sensitive information
    # Your function code here
    
    # Your code to calculate any other custom metric, like time to first/last token 
    
    return None # or output, custom_metric, response or any other output variable
```

6. Run your application as usual. The decorated functions will automatically log the function inputs, outputs, and relevant metadata to Amazon Kinesis Firehose, as well as perform evaluations on the responses, Knowledge Bases, and Agents.

For more detailed usage instructions, examples, and advanced configuration options, please refer to the package documentation.

## Contributing
If you'd like to contribute to this project, please follow the standard GitHub workflow:

1. Fork the repository
2. Create a new branch for your feature or bug fix
3. Make your changes and commit them with descriptive commit messages
4. Push your changes to your forked repository
5. Create a pull request against the main repository

Please ensure that your code follows the project's coding standards and includes appropriate tests.

## License
This project is licensed under the [MIT License](LICENSE).