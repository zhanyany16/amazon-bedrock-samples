{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude 3 Metadata Tagger\n",
    "---\n",
    "\n",
    "Use `Claude 3` to extract metadata from text. The schema for the metadata is provided as part of the prompt. This example uses synthetic data to demonstrate the metadata extraction capability for `Claude 3`. The extracted metadata is provided in JSON format so that it is parseable by downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLAUDE_MODEL_ID: str = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "REGION: str = \"us-west-2\"\n",
    "ENDPOINT_URL: str = f\"https://bedrock-runtime.{REGION}.amazonaws.com\"\n",
    "# Enter your schema below - \n",
    "YOUR_SCHEMA: Dict = {\n",
    "    \"properties\": {\n",
    "        \"article_title\": {\"type\": \"string\"},\n",
    "        \"author\": {\"type\": \"string\"},\n",
    "        \"topic\": {\"type\": \"string\", \"enum\": [\"quantum physics\",\n",
    "                                             \"classical mechanics\",\n",
    "                                             \"thermodynamics\",\n",
    "                                             \"relativity\",\n",
    "                                             \"other\"]},\n",
    "        \"publication_date\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The date the article was published, say \\\"date unknown\\\" if not found\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"article_title\", \"author\", \"topic\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example generated by Claude 3 Sonnet\n",
    "ORIGINAL_DOCS: List[str] = [\n",
    "    \"Title: Quantum Entanglement\\nAuthor: John Doe\\n\\nAn in-depth look at the fascinating world of quantum entanglement. Published 2022-03-04.\",\n",
    "    \"Title: The Laws of Thermodynamics\\nAuthor: Jane Smith\\n\\nA comprehensive guide to understanding the fundamental laws of thermodynamics\",\n",
    "    \"Title: Cosmic Inflation\\nAuthor: Michael Johnson\\n\\nExploring the theory of cosmic inflation and its implications for our universe\",\n",
    "    \"Title: Neutrino Physics\\nAuthor: Emily Wilson\\n\\nDiscovering the elusive nature of neutrinos and their role in particle physics\",\n",
    "    \"Title: Astrobiology\\nAuthor: David Thompson\\n\\nInvestigating the potential for life beyond Earth and the search for extraterrestrial intelligence\",\n",
    "    \"Title: Evolutionary Genetics\\nAuthor: Sarah Davis\\n\\nUnraveling the mysteries of how life evolves through the lens of genetics\",\n",
    "    \"Title: Plate Tectonics\\nAuthor: William Anderson\\n\\nUnderstanding the dynamic forces that shape the Earth's surface\",\n",
    "    \"Title: Origin of Life\\nAuthor: Robert Brown\\n\\nUnraveling the mysteries of how life began on Earth. Data published: March 1674.\",\n",
    "    \"Title: Relativity and Spacetime\\nAuthor: Amanda Miller\\n\\nUnderstanding Einstein's groundbreaking theories of relativity\",\n",
    "    \"Title: Dark Matter and Dark Energy\\nAuthor: Daniel Harris\\n\\nInvestigating the enigmatic components that shape our universe\",\n",
    "    \"Title: Molecular Nanotechnology\\nAuthor: Sophia Clark\\n\\nEngineering at the molecular scale for revolutionary applications\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "METADATA_TAGGER_PROMPT: str = \"\"\"\n",
    "Human: you are a metadata tagger, see the following schema and tag the data that follows to extract the metadata fields listed in the schema. You have \n",
    "to at least provide everything in the metadata tagger that is given in \"required\" parameter within the schema. Provide the response in JSON without any tags around the\n",
    "response.\n",
    "\n",
    "<schema>\n",
    "{schema}\n",
    "</schema>\n",
    "\n",
    "<data>\n",
    "{text}\n",
    "</data>\n",
    "\n",
    "Assistant: Here is the metadata information as JSON:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to generate the prompt for Claude\n",
    "def _generate_prompt(schema: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    This function returns a fully formatted prompt that claude takes in to create a \n",
    "    metadata tagger\n",
    "    \"\"\"\n",
    "    prompt: Optional[str] = None\n",
    "    try:\n",
    "        prompt = METADATA_TAGGER_PROMPT.format(schema=json.dumps(schema,\n",
    "                                                                 indent=2),\n",
    "                                               text=text)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"schema or text not provided: {e}\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simple function to get a final summary on all of the data provided from LLM as a judge\n",
    "def extract_metadata_from_text(schema: str, data: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    This function takes in the prompt that checks whether the text file has a response to the question and if not, \n",
    "    returns \"not found\" to move to the next hit\n",
    "    \"\"\"\n",
    "    prompt = _generate_prompt(schema, data)\n",
    "    logger.debug(f\"prompt: {prompt}\")\n",
    "    body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 2000,\n",
    "        \"temperature\": 0.1,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        bedrock = boto3.client(service_name=\"bedrock-runtime\",\n",
    "                               endpoint_url=ENDPOINT_URL)\n",
    "        response = bedrock.invoke_model(modelId=CLAUDE_MODEL_ID,\n",
    "                                        body=body)\n",
    "        response_body = json.loads(response['body'].read().decode(\"utf-8\"))\n",
    "        # read the response text as string and then convert it into a dictionary\n",
    "        response_as_str: str = response_body['content'][0]['text']\n",
    "        # make it easy to convert to JSON by removing unnecessary formatting\n",
    "        response_as_str = response_as_str.strip().replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "        llm_response = json.loads(response_as_str)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"exception={e}\")\n",
    "        llm_response = None\n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ready to extract metadata from docs\n",
    "enhanced_documents = []\n",
    "for doc in ORIGINAL_DOCS:\n",
    "    metadata = extract_metadata_from_text(YOUR_SCHEMA, doc)\n",
    "    enhanced_doc = {\n",
    "        \"page_content\": doc,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "    enhanced_documents.append(enhanced_doc)\n",
    "\n",
    "logger.info(f\"==== original content with extracted metadata ====\")\n",
    "for doc in enhanced_documents:\n",
    "    logger.info(f\"Data: {doc['page_content']}\\n\\nMetadata: {json.dumps(doc['metadata'], indent=4)}\\n\\n\")\n",
    "    logger.info(\"---------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
